name: All Tests
run-name: ${{ inputs.test_name }}${{ inputs.test_dbs }}

on:
  pull_request:
  push:
    branches:
      - main
      - cloud/*
      - feature/*
      - release/*

  workflow_dispatch:
    inputs:
      commit:
        description: "Commit SHA"
        required: true
      run_single_functional_test:
        description: "Run a single functional test"
        type: boolean
        default: false
      run_single_unit_test:
        description: "Run a single unit test (INSTEAD of functional test)"
        type: boolean
        default: false
      unit_test_directory:
        description: "[Unit Test Only] Directory to run unit tests in"
        type: string
        default: "./temporal"
      n_runs:
        description: "Number of times to repeat the test per database type (except for unit tests, start with n=25 or lower to avoid OOMKill)"
        type: number
        default: 1
      test_name:
        description: "Name of the test to run (i.e. 'TestAcquireShard_DeadlineExceededErrorSuite' or 'TestFunctionalSuite/TestUpdateWorkflow')"
        type: string
      timeout_minutes:
        description: "Test timeout in minutes"
        type: number
        default: 120
      test_runner:
        description: "Which runner to use. Choose higher RAM if your n_runs is high."
        type: choice
        default: "16GB RAM (ubuntu-latest)"
        options:
          - "16GB RAM (ubuntu-latest)"
          - "64GB RAM (ubuntu-latest-16-cores)"
      test_dbs:
        description: 'List of DBs to test on (i.e. ["sqlite", "cassandra", "mysql8", "postgres12"])'
        type: string
        default: '["sqlite"]'

concurrency: # Auto-cancel existing runs in the PR when a new commit is pushed
  group: run-tests-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

env:
  # For workflow_dispatch: use the given commit.
  # For pull_request: use the head of the PR branch (not the merge branch which is the default!)
  # For push: use the pushed commit.
  COMMIT: ${{ github.event.inputs.commit || github.event.pull_request.head.sha || github.sha }}
  PR_BASE_COMMIT: ${{ github.event.pull_request.base.sha }}
  DOCKER_COMPOSE_FILE: ./develop/github/docker-compose.yml
  TEMPORAL_VERSION_CHECK_DISABLED: 1

jobs:
  set-up-single-test:
    name: Set up single test
    runs-on: ubuntu-latest
    outputs:
      shard_indices: ${{ steps.generate_output.outputs.shard_indices }}
      total_shards: ${{ steps.generate_output.outputs.shards }}
      github_timeout: ${{ steps.generate_output.outputs.github_timeout }}
      test_timeout: ${{ steps.generate_output.outputs.test_timeout }}
      single_test_args: ${{ steps.generate_output.outputs.single_test_args }}
      runs_on: ${{ steps.generate_output.outputs.runs_on }}
      dbs: ${{ inputs.test_dbs }}
      modified_unit_test_suites: ${{ env.modified_unit_test_suites }}
      modified_integration_test_suites: ${{ env.modified_integration_test_suites }}
      modified_functional_test_suites: ${{ env.modified_functional_test_suites }}
      modified_functional_ndc_test_suites: ${{ env.modified_functional_ndc_test_suites }}
      modified_functional_xdc_test_suites: ${{ env.modified_functional_xdc_test_suites }}
    steps:
      - id: generate_output
        run: |
          shards=3
          timeout=35   # update this to TEST_TIMEOUT if you update the Makefile
          runs_on='["ubuntu-latest"]'
          if [[ "${{ inputs.run_single_functional_test }}" == "true" || "${{ inputs.run_single_unit_test }}" == "true" ]]; then
            shards=1
            timeout=${{ inputs.timeout_minutes }}
            single_test_args="-run ${{ inputs.test_name }} -count ${{ inputs.n_runs }}"
            if [[ "${{ inputs.test_runner }}" == "64GB RAM (ubuntu-latest-16-cores)" ]]; then
              runs_on='[ "ubuntu-latest-16-cores" ]'
            fi
          fi
          {
            echo "shard_indices=[ $(seq -s, 0 $((shards-1))) ]"
            echo "shards=$shards"
            echo "github_timeout=$((timeout+5))"
            echo "test_timeout=${timeout}m"
            echo "single_test_args=$single_test_args"
            echo "runs_on=$runs_on"
          } >> "$GITHUB_OUTPUT"
      - id: cat_output
        run: |
          cat "$GITHUB_OUTPUT"

      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ env.COMMIT }}
          fetch-depth: 0

      - name: Fetch base branch
        run: git fetch origin ${{ github.event.pull_request.base.ref }}:${{ github.event.pull_request.base.ref }}

      - name: Compute merge base
        if: ${{ github.event_name == 'pull_request' }}
        run: |
          MERGE_BASE="$(git merge-base "${{ env.COMMIT }}" "${{ github.event.pull_request.base.ref }}")"
          echo "MERGE_BASE=${MERGE_BASE}" >> "$GITHUB_ENV"

          set -exuo pipefail

          go run ./cmd/tools/test/find_altered_tests.go \
            -c unit \
            -c integration \
            -c functional \
            -c functional_ndc \
            -c functional_xdc \
            -s "${MERGE_BASE}" \
            -t "${COMMIT}" | tee -a "$GITHUB_ENV"
        shell: bash

  pre-build:
    name: Pre-build for cache
    strategy:
      fail-fast: false
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ env.COMMIT }}

      - uses: actions/setup-go@v5
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          go-version-file: "go.mod"
          cache: false  # do our own caching

      - name: Restore dependencies
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        id: restore-deps
        uses: actions/cache/restore@v4
        with:
          path: ~/go/pkg/mod
          key: go-${{ runner.os }}${{ runner.arch }}-deps-${{ hashFiles('go.sum') }}

      - run: make pre-build-functional-test-coverage
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}

      - name: Save dependencies
        uses: actions/cache/save@v4
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test && steps.restore-deps.outputs.cache-hit != 'true' }}
        with:
          path: ~/go/pkg/mod
          key: ${{ steps.restore-deps.outputs.cache-primary-key }}

      - name: Save build outputs
        uses: actions/cache/save@v4
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          path: ~/.cache/go-build
          key: go-${{ runner.os }}${{ runner.arch }}-build-${{ env.COMMIT }}

  misc-checks:
    name: Misc checks
    needs: pre-build
    strategy:
      fail-fast: false
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ env.COMMIT }}
          # buf-breaking tries to compare HEAD against merge base so we need to be able to find it
          fetch-depth: 100

      - uses: actions/setup-go@v5
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          go-version-file: "go.mod"
          cache: false  # do our own caching

      - name: Restore dependencies
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        uses: actions/cache/restore@v4
        with:
          path: ~/go/pkg/mod
          key: go-${{ runner.os }}${{ runner.arch }}-deps-${{ hashFiles('go.sum') }}

      - name: Restore build outputs
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        uses: actions/cache/restore@v4
        with:
          path: ~/.cache/go-build
          key: go-${{ runner.os }}${{ runner.arch }}-build-${{ env.COMMIT }}

      - uses: arduino/setup-protoc@v3
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}

      - run: GOOS=windows GOARCH=amd64 make clean-bins bins
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}

      - run: GOOS=darwin GOARCH=arm64 make clean-bins bins
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}

      - run: make clean-bins ci-build-misc
        if: ${{ !inputs.run_single_functional_test && !inputs.run_single_unit_test }}

  unit-test:
    if: ${{ inputs.run_single_functional_test != true }}
    name: Unit test
    needs: [pre-build, set-up-single-test]
    strategy:
      fail-fast: false
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ env.COMMIT }}

      - uses: actions/setup-go@v5
        with:
          go-version-file: "go.mod"
          cache: false  # do our own caching

      - name: Restore dependencies
        uses: actions/cache/restore@v4
        with:
          path: ~/go/pkg/mod
          key: go-${{ runner.os }}${{ runner.arch }}-deps-${{ hashFiles('go.sum') }}

      - name: Restore build outputs
        uses: actions/cache/restore@v4
        with:
          path: ~/.cache/go-build
          key: go-${{ runner.os }}${{ runner.arch }}-build-${{ env.COMMIT }}

      - name: Run unit tests
        timeout-minutes: 15
        run: make unit-test-coverage
        env:
          UNIT_TEST_DIRS: ${{ inputs.unit_test_directory }}
          TEST_ARGS: ${{ needs.set-up-single-test.outputs.single_test_args }}
          TEST_TIMEOUT: ${{ needs.set-up-single-test.outputs.test_timeout }}

      - name: Generate test summary
        uses: mikepenz/action-junit-report@v5.0.0-rc01
        if: failure()
        with:
          report_paths: ./.testoutput/junit.*.xml
          detailed_summary: true
          check_annotations: false
          annotate_only: true
          skip_annotations: true

      - name: Upload code coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          directory: ./.testoutput
          flags: unit-test

      - name: Upload test results to Codecov
        if: ${{ !cancelled() }}
        uses: codecov/test-results-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          directory: ./.testoutput
          flags: unit-test

      - name: Upload test results to GitHub
        # Can't pin to major because the action linter doesn't recognize the include-hidden-files flag.
        uses: actions/upload-artifact@v4.4.3
        if: ${{ !cancelled() && !inputs.run_single_unit_test }}
        with:
          name: junit-xml--${{github.run_id}}--${{github.run_attempt}}--unit-test
          path: ./.testoutput/junit.*.xml
          include-hidden-files: true
          retention-days: 28

      # Ensure this doesn't contribute to the junit output.
      - name: Flaky Unit Test Detection
        if: ${{ !cancelled() && !inputs.run_single_unit_test && env.MODIFIED_TEST_SUITES != '' }}
        timeout-minutes: 30
        run: |
          echo "Detecting flaky unit tests: ${{ needs.set-up-single-test.outputs.modified_unit_test_suites }}"
          make unit-test
        env:
          FAILED_TEST_RETRIES: "0" # not retrying failed tests intentionally here since we're trying to detect flakes
          TEST_ARGS: "-run=${{ needs.set-up-single-test.outputs.modified_unit_test_suites }} -count=10"
          TEST_TIMEOUT: 35

  test-status:
    if: always()
    name: Test Status
    needs:
      - misc-checks
      - unit-test
    runs-on: ubuntu-latest
    env:
      RESULTS: ${{ toJSON(needs.*.result) }}
    steps:
      - name: Check results
        run: |
          if [[ "${{ inputs.run_single_functional_test }}" != "true" ]]; then
            # if in all-tests mode, all statuses must be success
            if [[ -n $(echo "$RESULTS" | jq '.[] | select (. != "success")') ]]; then
              exit 1
            fi
          else
            # if in single-test mode, skipped status is ok, failure is failure
            if [[ -n $(echo "$RESULTS" | jq '.[] | select (. == "failure")') ]]; then
              exit 1
            fi
          fi